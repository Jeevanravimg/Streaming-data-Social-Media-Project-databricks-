ğŸ“˜ Real-Time Social Media Streaming Project (Databricks)
ğŸ“Œ Project Overview

This project implements a real-time social media streaming data pipeline using Databricks, Delta Live Tables (DLT), and Unity Catalog.
Synthetic social media data (users, posts, comments, likes) is continuously generated and ingested as JSON files, processed through a Bronze â†’ Silver â†’ Gold Medallion Architecture, and exposed for analytics and dashboards.

The project demonstrates production-grade streaming ingestion, data quality enforcement, transformations, and business-level aggregations.

ğŸ—ï¸ Architecture Overview
Fake Data Generator (JSON)
        â†“
Unity Catalog Volume (Raw JSON Files)
        â†“
Bronze Layer (DLT Streaming Tables)
        â†“
Silver Layer (Cleaned & Validated Tables)
        â†“
Gold Layer (Aggregated Analytics Tables)
        â†“
Dashboards & Insights

ğŸ› ï¸ Technologies Used

Databricks

Delta Live Tables (DLT)

Apache Spark Structured Streaming

Unity Catalog

Python

Faker

GitHub

ğŸ“‚ Project Structure
Streaming-data-Social-Media-Project-databricks/
â”‚
â”œâ”€â”€ POC_Streaming_Jeevan/
â”‚   â””â”€â”€ Data_Generation_JSON        # Continuous JSON data generator
â”‚
â”œâ”€â”€ Social_Media_Pipeline/
â”‚   â””â”€â”€ transformations/
â”‚       â”œâ”€â”€ Bronze_Layer.py         # DLT Bronze streaming ingestion
â”‚       â”œâ”€â”€ Silver_Layer.py         # DLT Silver cleaning & quality checks
â”‚       â””â”€â”€ Gold_Layer.py           # DLT Gold aggregations
â”‚
â”œâ”€â”€ Social_Media_Dashboards         # Databricks dashboards
â”œâ”€â”€ README.md

ğŸ“¦ Data Generation (Streaming Source)
ğŸ”¹ Description

Synthetic social media data is generated continuously using the Faker library.
The generator runs multiple threads in parallel to simulate real-time event streams.

ğŸ”¹ Data Types Generated

Users

Posts

Comments

Likes / Reactions

ğŸ”¹ Storage Location (Unity Catalog Volume)
/Volumes/kusha_solutions/jeevan_streaming/my_volume/Raw_JSON_Files/
â”œâ”€â”€ users/
â”œâ”€â”€ posts/
â”œâ”€â”€ comments/
â””â”€â”€ likes/

ğŸ”¹ Key Characteristics

JSON format

Continuous file generation

Includes randomness and high-volume interaction patterns

Fully synthetic (no real user data)

ğŸ¥‰ Bronze Layer â€” Raw Streaming Ingestion
ğŸ”¹ Description

The Bronze layer ingests raw JSON files using Databricks Auto Loader with Spark Structured Streaming.

ğŸ”¹ Features

Streaming ingestion (readStream)

Explicit schema enforcement

Metadata capture:

Ingestion timestamp

Source file path

Fault-tolerant schema tracking

ğŸ”¹ Bronze Tables

bronze_users

bronze_posts

bronze_comments

bronze_likes

ğŸ”¹ Schema Checkpoint Location
/Volumes/kusha_solutions/jeevan_streaming/my_volume/autoloader_schema/

ğŸ¥ˆ Silver Layer â€” Data Cleaning & Quality Enforcement
ğŸ”¹ Description

The Silver layer cleans and standardizes data from the Bronze layer and applies data quality rules using DLT expectations.

ğŸ”¹ Key Transformations

Deduplication based on primary keys

Null handling with default values

Text standardization (trim, lowercase)

Processed timestamp for auditing

ğŸ”¹ Data Quality Rules (DLT Expectations)

Mandatory fields must not be null

Email format validation

Referential integrity checks

ğŸ”¹ Silver Tables

silver_users

silver_posts

silver_comments

silver_likes

ğŸ¥‡ Gold Layer â€” Business Aggregations
ğŸ”¹ Description

The Gold layer produces analytics-ready tables optimized for reporting and dashboards.

ğŸ”¹ Gold Tables Created
1ï¸âƒ£ Top Active Users

gold_top_active_users

Top 10 users by total engagement

Engagement score = likes + comments

2ï¸âƒ£ Popular Posts

gold_popular_posts

Top 10 posts by combined likes and comments

3ï¸âƒ£ Daily Engagement Trends

gold_daily_engagement_trends

Daily likes, comments, and total engagement trends

4ï¸âƒ£ User Engagement Summary

gold_user_engagement_summary

Average likes and comments per post per user

ğŸ“Š Dashboards
ğŸ”¹ Description

Databricks dashboards are built on top of Gold tables to visualize real-time insights.

ğŸ”¹ Dashboard Queries
SELECT * FROM kusha_solutions.jeevan_streaming.gold_top_active_users;
SELECT * FROM kusha_solutions.jeevan_streaming.gold_popular_posts;
SELECT * FROM kusha_solutions.jeevan_streaming.gold_daily_engagement_trends;
SELECT * FROM kusha_solutions.jeevan_streaming.gold_user_engagement_summary;

â–¶ï¸ How to Run the Project (Databricks)
Step 1: Clone Repository
git clone https://github.com/Jeevanravimg/real-time-social-media-streaming.git

Step 2: Open in Databricks

Workspace â†’ Home â†’ Create â†’ Git Folder

Paste repository URL

Step 3: Run Data Generator

Open POC_Streaming_Jeevan/Data_Generation_JSON

Run notebook to start continuous JSON generation

Step 4: Configure DLT Pipeline

Create a Delta Live Tables pipeline

Add:

Bronze_Layer.py

Silver_Layer.py

Gold_Layer.py

Set target schema:

kusha_solutions.jeevan_streaming

Step 5: Start Pipeline

Run pipeline in Continuous or Triggered mode

ğŸ” Data Disclaimer

All data used in this project is synthetically generated using Faker and does not represent real users or social media activity.

ğŸ¯ Key Learnings

Real-time streaming ingestion with Auto Loader

Delta Live Tables with expectations

Medallion architecture for streaming workloads

Production-ready data quality enforcement

Analytical aggregation for dashboards

ğŸ‘¤ Author

Jeevan M G
Databricks | Data Engineering | Lakehouse Architecture